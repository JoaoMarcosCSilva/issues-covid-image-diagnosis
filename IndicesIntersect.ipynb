{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "I0000 00:00:1653958818.577289  549031 tpu_initializer_helper.cc:165] libtpu.so already in use by another process probably owned by another user. Run \"$ sudo lsof -w /dev/accel0\" to figure out which process is using the TPU. Not attempting to load libtpu.so in this process.\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/home/joao/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Starts the autoreload extension, which allows editing the .py files with the notebook running and automatically imports the latest changes\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import trim_duplicates, model, network, gradcam, plots\n",
    "from dataset import Dataset\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax\n",
    "import sklearn\n",
    "import wandb\n",
    "from trim_duplicates import DuplicatesData\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#assert jax.local_device_count() >= 8\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "SEED = 14\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def basemodel_process(x): return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 7241465856 bytes == 0x950c94000 @  0x7f7a6f1fe680 0x7f7a6f21f824 0x7f7a6498df34 0x7f7a6498e64f 0x7f7a649ec4be 0x7f7a649ed121 0x7f7a64a90c96 0x5f2fb9 0x5f3446 0x56fb02 0x56822a 0x5f6033 0x56b115 0x56822a 0x5f6033 0x56ef97 0x56822a 0x5f6033 0x56b115 0x56822a 0x68c1e7 0x5ff1f4 0x5c3cb0 0x569f5e 0x5002e8 0x56b95e 0x5002e8 0x56b95e 0x5002e8 0x503f46 0x56a136\n",
      "tcmalloc: large alloc 7241465856 bytes == 0x1113814000 @  0x7f7a6f1fe680 0x7f7a6f21f824 0x7f7a6498df34 0x7f7a6498e64f 0x7f7a649eb4ba 0x7f7a649eb598 0x7f7a64a7e38a 0x7f7a64a7edeb 0x50fc9c 0x56a3a0 0x56822a 0x5f6033 0x56b115 0x56822a 0x68c1e7 0x5ff1f4 0x5c3cb0 0x569f5e 0x5002e8 0x56b95e 0x5002e8 0x56b95e 0x5002e8 0x503f46 0x56a136 0x5f5e56 0x569f5e 0x5f5e56 0x56a136 0x56822a 0x5f6033\n",
      "tcmalloc: large alloc 7241465856 bytes == 0x12c3214000 @  0x7f7a6f1fe680 0x7f7a6f21f824 0x7f7a6498df34 0x7f7a6498e64f 0x7f7a649eb4ba 0x7f7a64a917f9 0x7f7a64a91f47 0x7f7a64a9209c 0x6b224d 0x7f7a649d4574 0x5f305a 0x5f3446 0x56f1ca 0x56822a 0x5f6033 0x56ef97 0x5f5e56 0x59ba6e 0x5f33af 0x56f1ca 0x56822a 0x5f6033 0x56b115 0x56822a 0x68c1e7 0x5ff1f4 0x5c3cb0 0x569f5e 0x5002e8 0x56b95e 0x5002e8\n",
      "tcmalloc: large alloc 16644833280 bytes == 0x1473414000 @  0x7f7a6f1fe680 0x7f7a6f21f824 0x7f7a6498df34 0x7f7a6498e64f 0x7f7a649ec4be 0x7f7a649ed121 0x7f7a64a90c96 0x5f2fb9 0x5f3446 0x56fb02 0x56822a 0x5f6033 0x56b115 0x56822a 0x5f6033 0x56ef97 0x56822a 0x5f6033 0x56b115 0x56822a 0x68c1e7 0x5ff1f4 0x5c3cb0 0x569f5e 0x5002e8 0x56b95e 0x5002e8 0x56b95e 0x5002e8 0x503f46 0x56a136\n",
      "tcmalloc: large alloc 16644833280 bytes == 0x18545d4000 @  0x7f7a6f1fe680 0x7f7a6f21f824 0x7f7a6498df34 0x7f7a6498e64f 0x7f7a649eb4ba 0x7f7a649eb598 0x7f7a64a7e38a 0x7f7a64a7edeb 0x50fc9c 0x56a3a0 0x56822a 0x5f6033 0x56b115 0x56822a 0x68c1e7 0x5ff1f4 0x5c3cb0 0x569f5e 0x5002e8 0x56b95e 0x5002e8 0x56b95e 0x5002e8 0x503f46 0x56a136 0x5f5e56 0x569f5e 0x5f5e56 0x56a136 0x56822a 0x5f6033\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(SEED)\n",
    "rng = jax.random.split(jax.random.PRNGKey(1))[0]\n",
    "dataset_mendeley = Dataset.load(\"mendeley\", rng=rng, official_split=True)\n",
    "dataset_tawsifur = Dataset.load(\"tawsifur\", rng=rng, official_split=True)\n",
    "print(\"Loaded mendeley\", dataset_mendeley.classnames)\n",
    "print(\"Loaded tawsifur\", dataset_tawsifur.classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dup_data/cv_mendeley_0.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m                 imgs[\u001b[38;5;28mlen\u001b[39m(imgs)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m: ds\u001b[38;5;241m.\u001b[39mx_all[i,:,:,:], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m other_dups_map \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m\"\u001b[39m })\n\u001b[1;32m     66\u001b[0m     plots\u001b[38;5;241m.\u001b[39mcompare_n_images(imgs, rows\u001b[38;5;241m=\u001b[39mmax_rows)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mshow_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_mendeley\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m### COUNTS DUPS INTERSECTION ACROSS CROSS VALIDATION SETS ###\u001b[39;00m\n\u001b[1;32m     72\u001b[0m actual_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtawsifur\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mshow_diff\u001b[0;34m(ds, global_set, max_rows)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_diff\u001b[39m(ds, global_set, max_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m     24\u001b[0m     actual_name \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m     dups \u001b[38;5;241m=\u001b[39m \u001b[43mDuplicatesData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdup_data/cv_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mactual_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_0.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     dups_pix \u001b[38;5;241m=\u001b[39m DuplicatesData\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdup_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m actual_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_pix.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m global_set \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m global_set \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpix\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/mnt/xray_duplicates_detector/trim_duplicates.py:26\u001b[0m, in \u001b[0;36mDuplicatesData.load\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(filepath):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dup_data/cv_mendeley_0.pickle'"
     ]
    }
   ],
   "source": [
    "def report_dups(title, count, ds):\n",
    "    print(title + \":\", count, \"(\" + str(round(count / ds.x_all.shape[0] * 1000)/10) + \"%)\")\n",
    "\n",
    "def is_dup(indices, i, dont_count):\n",
    "    for v in indices:\n",
    "        if len(v) > 1 and i not in dont_count and i in v:\n",
    "            for j in v:\n",
    "                if j != i:\n",
    "                    dont_count[j] = True\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def count_dups(groups, ds):\n",
    "    dont_count = {}\n",
    "    dups_count = 0\n",
    "\n",
    "    for i in range(ds.x_all.shape[0]):\n",
    "        if is_dup(groups, i, dont_count):\n",
    "            dups_count += 1\n",
    "    \n",
    "    return dups_count\n",
    "\n",
    "def show_diff(ds, global_set, max_rows=4):\n",
    "    actual_name = ds.name.split(\"/\")[-1]\n",
    "    dups = DuplicatesData.load(\"dup_data/cv_\" + actual_name + \"_0.pickle\")\n",
    "    dups_pix = DuplicatesData.load(\"dup_data/\" + actual_name + \"_pix.pickle\")\n",
    "\n",
    "    assert global_set == \"embed\" or global_set == \"pix\"\n",
    "\n",
    "    if global_set == \"embed\":\n",
    "        global_set = dups.indices\n",
    "        other_set = dups_pix.indices\n",
    "    else:\n",
    "        global_set = dups_pix.indices\n",
    "        other_set = dups.indices\n",
    "    \n",
    "    diff = global_set - dups.indices.intersection(dups_pix.indices)\n",
    "    \n",
    "    total_dups_two_sets = 0\n",
    "    dont_count = {}\n",
    "\n",
    "    for i in range(ds.x_all.shape[0]):       \n",
    "        if is_dup(dups, i, dont_count) and is_dup(dups_pix, i, dont_count):\n",
    "            total_dups_two_sets += 1\n",
    "\n",
    "    report_dups(\"Total pix dups\", count_dups(dups_pix.indices, ds), ds)\n",
    "    report_dups(\"Total embed dups\", count_dups(dups.indices, ds), ds)\n",
    "    # report_dups(\"Intersection\", total_dups_two_sets, ds)\n",
    "\n",
    "    #assert jnp.all(ds.rng == dups.rng) and jnp.all(ds.rng == dups_pix.rng)\n",
    "\n",
    "    other_dups_map = {}\n",
    "    for group in other_set:\n",
    "        if len(group) > 1:\n",
    "            for i in group:\n",
    "                other_dups_map[i] = True\n",
    "        \n",
    "    imgs = []\n",
    "    for v in diff:\n",
    "        imgs.append([])\n",
    "        if len(v) > 1:\n",
    "            for i in v:\n",
    "                print(i, ds.paths_all[i])\n",
    "                imgs[len(imgs)-1].append({ \"img\": ds.x_all[i,:,:,:], \"color\": \"red\" if i not in other_dups_map else \"black\" })\n",
    "    \n",
    "    plots.compare_n_images(imgs, rows=max_rows)\n",
    "\n",
    "show_diff(dataset_mendeley, \"embed\")\n",
    "\n",
    "### COUNTS DUPS INTERSECTION ACROSS CROSS VALIDATION SETS ###\n",
    "\n",
    "actual_name = \"tawsifur\"\n",
    "ds = dataset_tawsifur\n",
    "\n",
    "cvs = []\n",
    "for i in range(5):\n",
    "    cvs.append(DuplicatesData.load(\"dup_data/cv_\" + actual_name + \"_\" + str(i) + \".pickle\"))\n",
    "cvs.append(DuplicatesData.load(\"dup_data/\" + actual_name + \"_pix.pickle\"))\n",
    "\n",
    "dups_in_all = 0\n",
    "dont_count = {}\n",
    "\n",
    "for i in range(ds.x_all.shape[0]):   \n",
    "    in_all = True\n",
    "    for cv in range(len(cvs)):\n",
    "        if not is_dup(cvs[cv].indices, i, dont_count):\n",
    "            in_all = False\n",
    "            break\n",
    "    \n",
    "    if in_all:\n",
    "        dups_in_all += 1\n",
    "\n",
    "report_dups(\"INTERSECAO DE TODOS CV E DOS EMBEDDINGS\", dups_in_all, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dup_data/mendeley_custom.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                 imgs[\u001b[38;5;28mlen\u001b[39m(imgs)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m: ds\u001b[38;5;241m.\u001b[39mx_all[i,:,:,:], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m other_dups_map \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m\"\u001b[39m })\n\u001b[1;32m     37\u001b[0m     plots\u001b[38;5;241m.\u001b[39mcompare_n_images(imgs, rows\u001b[38;5;241m=\u001b[39mmax_rows)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mcustom_show_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_mendeley\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mcustom_show_diff\u001b[0;34m(ds, global_set, max_rows)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_show_diff\u001b[39m(ds, global_set, max_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m      2\u001b[0m     actual_name \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m     dups \u001b[38;5;241m=\u001b[39m \u001b[43mDuplicatesData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdup_data/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mactual_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_custom.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     dups_pix \u001b[38;5;241m=\u001b[39m DuplicatesData\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdup_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m actual_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_pix.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m global_set \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m global_set \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpix\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/mnt/xray_duplicates_detector/trim_duplicates.py:26\u001b[0m, in \u001b[0;36mDuplicatesData.load\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(filepath):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dup_data/mendeley_custom.pickle'"
     ]
    }
   ],
   "source": [
    "def custom_show_diff(ds, global_set, max_rows=4):\n",
    "    actual_name = ds.name.split(\"/\")[-1]\n",
    "    dups = DuplicatesData.load(\"dup_data/\" + actual_name + \"_custom.pickle\")\n",
    "    dups_pix = DuplicatesData.load(\"dup_data/\" + actual_name + \"_pix.pickle\")\n",
    "\n",
    "    assert global_set == \"embed\" or global_set == \"pix\"\n",
    "\n",
    "    if global_set == \"embed\":\n",
    "        global_set = dups.indices\n",
    "        other_set = dups_pix.indices\n",
    "    else:\n",
    "        global_set = dups_pix.indices\n",
    "        other_set = dups.indices\n",
    "    \n",
    "    diff = global_set - dups.indices.intersection(dups_pix.indices)\n",
    "    \n",
    "    print(\"Total embed dups:\", len(dups.indices))\n",
    "    print(\"Total pix dups:\", len(dups_pix.indices))\n",
    "    print(\"Complement of difference:\", len(diff))\n",
    "    \n",
    "    #assert jnp.all(ds.rng == dups.rng) and jnp.all(ds.rng == dups_pix.rng)\n",
    "\n",
    "    other_dups_map = {}\n",
    "    for group in other_set:\n",
    "        if len(group) > 1:\n",
    "            for i in group:\n",
    "                other_dups_map[i] = True\n",
    "        \n",
    "    imgs = []\n",
    "    for v in diff:\n",
    "        imgs.append([])\n",
    "        if len(v) > 1:\n",
    "            for i in v:\n",
    "                print(i, ds.paths_all[i])\n",
    "                imgs[len(imgs)-1].append({ \"img\": ds.x_all[i,:,:,:], \"color\": \"red\" if i not in other_dups_map else \"black\" })\n",
    "    \n",
    "    plots.compare_n_images(imgs, rows=max_rows)\n",
    "\n",
    "custom_show_diff(dataset_mendeley, \"embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 7241465856 bytes == 0x6cae1a000 @  0x7fe52e6ab680 0x7fe52e6cc824 0x7fe523e3af34 0x7fe523e3b64f 0x7fe523e994be 0x7fe523e9a121 0x7fe523f3dc96 0x5f2fb9 0x5f3446 0x56fb02 0x56822a 0x5f6033 0x56b115 0x56822a 0x5f6033 0x5f2b87 0x56b7b0 0x56822a 0x5f6033 0x56ef97 0x56822a 0x5f6033 0x56b115 0x56822a 0x68c1e7 0x5ff1f4 0x5c3cb0 0x569f5e 0x5002e8 0x56b95e 0x5002e8\n",
      "tcmalloc: large alloc 7241465856 bytes == 0xaac6000 @  0x7fe52e6ab680 0x7fe52e6cc824 0x7fe52e6ccb8a 0x7fe3d705c37c 0x7fe3d2af0520 0x7fe3d2b00228 0x7fe3d2b03aac 0x7fe3d2a40fb2 0x7fe3d2818c88 0x7fe3d2800991 0x5f2fb9 0x5f3446 0x50aa8b 0x56ef97 0x56822a 0x5f6033 0x5f5869 0x664d7d 0x5f2c0e 0x56b7b0 0x56822a 0x5f6033 0x5f2b87 0x56b7b0 0x56822a 0x5f6033 0x5f5869 0x664d7d 0x5f2c0e 0x56b7b0 0x5f5e56\n"
     ]
    }
   ],
   "source": [
    "ds_name = \"mendeley\"\n",
    "rng = jax.random.PRNGKey(SEED)\n",
    "\n",
    "ds = Dataset.load(ds_name, rng=rng, official_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pix dups: 6580\n",
      "0.92664146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def sim(x,y):\n",
    "    return jnp.dot(x,y) / jnp.sqrt(jnp.dot(x,x) * jnp.dot(y,y))\n",
    "\n",
    "def show_stats(ds_name):\n",
    "    dups_pix = DuplicatesData.load(\"dup_data/\" + ds_name + \".pickle\")\n",
    "    print(\"Total pix dups:\", len(dups_pix.indices))\n",
    "    \n",
    "    L = ds.y_all.argmax(axis=1)\n",
    "    c = 0\n",
    "    \n",
    "    for d in dups_pix.indices:\n",
    "        x = np.asarray(d)\n",
    "        #print(x, L[x], L[x[0]], L[x] == L[x[0]])\n",
    "        if len(x) > 1:#np.all(L[x] == L[x[0]]) and len(x) > 1:\n",
    "            c +=1\n",
    "            \n",
    "            print(sim(ds.x_all[x[0],].reshape(-1), ds.x_all[x[1],].reshape(-1)))\n",
    "            \n",
    "            plots.compare_images(ds.x_all[x,], ds.x_all[x,], rows=3)\n",
    "            plt.show()\n",
    "    \n",
    "            if c > 4:\n",
    "                break\n",
    "            \n",
    "    print(\"Not dups\", c)\n",
    "\n",
    "show_stats(\"mendeley\")\n",
    "#show_stats(\"tawsifur\")\n",
    "#show_stats(\"covidx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset_tawsifur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dup_data/tawsifur.pickle', 'rb') as f:\n",
    "    dups = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dups = list(dups.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in dups:\n",
    "    labels = ds.y_all[np.array(dups[0])].argmax(1)\n",
    "    if labels.std() != 0:\n",
    "        print('deu ruim')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
