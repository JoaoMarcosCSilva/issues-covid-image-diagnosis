{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Starts the autoreload extension, which allows editing the .py files with the notebook running and automatically imports the latest changes\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports all the libraries used\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from umap import UMAP\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import haiku as hk\n",
    "import optax\n",
    "\n",
    "import resnet\n",
    "import data\n",
    "import train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NUM_CLASSES = 4\n",
    "SEED = 12\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "jax.config.update(\"jax_debug_nans\", False)\n",
    "classes = ['Normal', 'Pneumonia-Bacterial', 'COVID-19', 'Pneumonia-Viral']\n",
    "\n",
    "rng = jax.random.PRNGKey(SEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "(x_train, y_train), (x_test, y_test) = data.load_data('.', rng, test_size = 0.1)\n",
    "\n",
    "x_all = np.concatenate([x_test, x_train])\n",
    "y_all = np.concatenate([y_test, y_train])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model functions"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def forward(batch, is_training, return_representation = False):\n",
    "    net = resnet.ResNet18(num_classes = NUM_CLASSES, resnet_v2 = True)\n",
    "    if return_representation:\n",
    "        return net.embedding(batch, is_training)\n",
    "    else:\n",
    "        return net(batch, is_training, return_representation = return_representation)\n",
    "\n",
    "net = hk.transform_with_state(forward)\n",
    "schedule = optax.cosine_decay_schedule(1e-1, 30 * (len(x_train) // BATCH_SIZE))\n",
    "optim = optax.adamw(schedule, weight_decay = 1e-3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Duplicates Detector"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Gets functions for the model\n",
    "init_fn, loss_fn, grad_fn, update, predict, evaluate, train_epoch = train.get_network_fns(net, optim, BATCH_SIZE)\n",
    "\n",
    "# Initializes parameters and state\n",
    "params, state, optim_state = init_fn(rng)\n",
    "\n",
    "# Train the model for 30 epochs\n",
    "for i in range(30):\n",
    "    params, state, optim_state = train_epoch(params, state, optim_state, x_train, y_train, x_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Similarity Filter"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Finds the latent vectorsfor the entire dataset\n",
    "reprs = predict(params, state, x_all, return_representation = True)\n",
    "reprs = reprs.reshape(reprs.shape[0], -1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Given two matrices of shapes [n, dim] and [m, dim], returns a matrix [n, m] with all cosine similarities between the vectors\n",
    "\n",
    "@partial(jax.vmap, in_axes = (None, 0))\n",
    "@partial(jax.vmap, in_axes = (0, None))\n",
    "\n",
    "def sim(x,y):\n",
    "    return jnp.dot(x,y) / jnp.sqrt(jnp.dot(x,x) * jnp.dot(y,y))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Finds the cosine similarity between all images in the dataset\n",
    "sims = sim(reprs, reprs)\n",
    "\n",
    "# Removes the diagonal of the matrix, since all images have a similarity of 1 with themselves\n",
    "sims = sims - np.eye(sims.shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set of images to be removed\n",
    "remove = set()\n",
    "\n",
    "# For each image not yet removed, add all of its duplicates to the removed set\n",
    "\n",
    "for i in tqdm(range(len(x_all))):\n",
    "    if i not in remove:\n",
    "        remove = remove.union(set(list(np.nonzero(sims[i] > 0.99)[0])))\n",
    "\n",
    "print('Removed images:', len(remove))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Finds the indices of the images that will not to be removed\n",
    "keep = set(range(len(x_all))).difference(remove)\n",
    "keep = np.array(list(keep))\n",
    "\n",
    "# These indices are for the x_all and y_all arrays.\n",
    "# The tensor x_all, for example, is the concatenation of x_test and x_train\n",
    "\n",
    "# Converts keep indices to be used in the train and test tensors\n",
    "keep_test = keep[keep < len(x_test)]\n",
    "keep_train = keep[keep >= len(x_test)] - len(x_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Removes the duplicates from the train and test sets\n",
    "\n",
    "x_test_curated = x_test[keep_test]\n",
    "y_test_curated = y_test[keep_test]\n",
    "\n",
    "x_train_curated = x_train[keep_train]\n",
    "y_train_curated = y_train[keep_train]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Curated Dataset Training"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initializes parameters and state\n",
    "params_curated, state_curated, optim_state_curated = init_fn(jax.random.split(rng)[0])\n",
    "\n",
    "# Gets functions for the model\n",
    "init_fn, loss_fn, grad_fn, update, predict, evaluate, train_epoch = train.get_network_fns(net, optim, BATCH_SIZE)\n",
    "\n",
    "# Train the model for 30 epochs on the curated dataset\n",
    "for i in range(30):\n",
    "    params_curated, state_curated, optim_state_curated = train_epoch(params_curated, state_curated, optim_state_curated, x_train_curated, y_train_curated, x_test_curated, y_test_curated)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predicts the classes for the test set using the models trained on the original and on the curated dataset\n",
    "y_pred = predict(params, state, x_test)\n",
    "y_pred_curated = predict(params_curated, state_curated, x_test_curated)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (15,5))\n",
    "    \n",
    "sn.histplot(sims.max(0), ax = axs[0]).set(title = 'Distribution of the maximum similarity for the images in the dataset')\n",
    "\n",
    "plt.title('Images with similarity greater than 0.99 in each class')\n",
    "pd.Series(y_all[sims.max(0) > 0.99].argmax(1)).map(dict(zip(range(4), classes))).hist()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (20, 5))\n",
    "sn.heatmap(confusion_matrix(y_test.argmax(1), y_pred.argmax(1), normalize = 'true'), ax = axs[0], annot = True, xticklabels = classes, yticklabels = classes).set(title = 'Original Results')\n",
    "sn.heatmap(confusion_matrix(y_test_curated.argmax(1), y_pred_curated.argmax(1), normalize = 'true'), ax = axs[1], annot = True, xticklabels = classes, yticklabels = classes).set(title = 'Curated Results');"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = (15,7))\n",
    "\n",
    "reprs_curated = predict(params_curated, state_curated, x_all, return_representation = True, verbose = False)\n",
    "reprs_curated = reprs_curated.reshape(reprs_curated.shape[0], -1)\n",
    "\n",
    "umap = UMAP().fit_transform(reprs)\n",
    "umap_curated = UMAP().fit_transform(reprs_curated)\n",
    "\n",
    "df = pd.DataFrame(umap)\n",
    "df['class_id'] = y_all.argmax(1)\n",
    "df['Class'] = df['class_id'].map(lambda x: ['Normal', 'Pneumonia-Bacterial', 'COVID-19', 'Pneumonia-Viral'][x])\n",
    "\n",
    "sn.scatterplot(ax = axs[0], x = df[0], y = df[1], hue = df['Class']).set(title = 'UMAP of the Original Embeddings')\n",
    "\n",
    "df = pd.DataFrame(umap_curated)\n",
    "df['class_id'] = y_all.argmax(1)\n",
    "df['Class'] = df['class_id'].map(lambda x: ['Normal', 'Pneumonia-Bacterial', 'COVID-19', 'Pneumonia-Viral'][x])\n",
    "\n",
    "sn.scatterplot(ax = axs[1], x = df[0], y = df[1], hue = df['Class']).set(title = \"UMAP of the Curated Embeddings\");"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}